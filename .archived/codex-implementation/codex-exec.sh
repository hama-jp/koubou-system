#!/bin/bash
# Codex CLI exec wrapper for Ollama with proper flag placement

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆè¨­å®š
KOUBOU_HOME="$(cd "$(dirname "$0")/.." && pwd)"
PROJECT_ROOT="$(cd "$KOUBOU_HOME/.." && pwd)"

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š
cd "$PROJECT_ROOT"

# OllamaãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª
if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "âš ï¸  Ollama is not running. Starting Ollama..."
    OLLAMA_NUM_GPU=999 OLLAMA_GPU_LAYERS=999 ollama serve > "$KOUBOU_HOME/logs/ollama.log" 2>&1 &
    sleep 3
fi

echo "ğŸ¤– Codex CLI exec with Ollama (gpt-oss:20b)"
echo "ğŸ“ Project: $PROJECT_ROOT"
echo ""

# execã‚³ãƒãƒ³ãƒ‰ã®å¾Œã«ãƒ•ãƒ©ã‚°ã‚’é…ç½®ï¼ˆé‡è¦ï¼ï¼‰  
# Linuxç’°å¢ƒã§LandlockãŒç„¡ã„å ´åˆã®å¯¾å¿œ
export CODEX_UNSAFE_ALLOW_NO_SANDBOX=1

exec codex exec \
    --oss \
    --model "gpt-oss:20b" \
    --sandbox danger-full-access \
    -c "approval_policy=\"never\"" \
    -c "trust_level=\"trusted\"" \
    "$@"