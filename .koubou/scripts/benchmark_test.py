#!/usr/bin/env python3
"""
å·¥æˆ¿ã‚·ã‚¹ãƒ†ãƒ  ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
ãƒ¯ãƒ¼ã‚«ãƒ¼ã®æ€§èƒ½ã¨æ©Ÿèƒ½ã‚’ç·åˆçš„ã«è©•ä¾¡
"""

import json
import time
import requests
import statistics
from datetime import datetime
from typing import Dict, List, Any
from pathlib import Path

# è¨­å®š
API_URL = "http://localhost:8765/task/delegate"
HEADERS = {"Content-Type": "application/json"}
TEST_DIR = Path("/home/hama/project/koubou-system/benchmark_test_files")

class BenchmarkTest:
    def __init__(self):
        self.results = []
        self.test_categories = {
            "file_operations": [],
            "text_generation": [],
            "code_generation": [],
            "analysis": [],
            "translation": []
        }
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        TEST_DIR.mkdir(exist_ok=True)
        
    def measure_task(self, task_name: str, prompt: str, category: str, sync: bool = True) -> Dict[str, Any]:
        """ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦æ¸¬å®š"""
        print(f"  Testing: {task_name}...")
        
        payload = {
            "type": "general",
            "prompt": prompt,
            "sync": sync
        }
        
        start_time = time.time()
        try:
            response = requests.post(API_URL, json=payload, headers=HEADERS, timeout=120)
            elapsed_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                success = result.get("result", {}).get("success", False) if sync else True
                output = result.get("result", {}).get("output", "") if sync else "Async task submitted"
                
                test_result = {
                    "name": task_name,
                    "category": category,
                    "success": success,
                    "time": elapsed_time,
                    "output_length": len(output),
                    "sync": sync
                }
                
                self.results.append(test_result)
                self.test_categories[category].append(test_result)
                
                return test_result
            else:
                print(f"    âŒ HTTP Error: {response.status_code}")
                return {"name": task_name, "success": False, "error": f"HTTP {response.status_code}"}
                
        except Exception as e:
            print(f"    âŒ Error: {e}")
            return {"name": task_name, "success": False, "error": str(e)}
    
    def run_file_operation_tests(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ“ File Operation Tests")
        print("=" * 50)
        
        # ãƒ†ã‚¹ãƒˆ1: ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        self.measure_task(
            "Create test file",
            f"Create a file at {TEST_DIR}/test_output.txt with content 'Benchmark test file created at ' followed by the current timestamp",
            "file_operations"
        )
        
        # ãƒ†ã‚¹ãƒˆ2: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Š
        self.measure_task(
            "Read file",
            f"Read the file at {TEST_DIR}/test_output.txt and tell me what it contains",
            "file_operations"
        )
        
        # ãƒ†ã‚¹ãƒˆ3: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒªã‚¹ãƒˆ
        self.measure_task(
            "List directory",
            f"List all files in the directory {TEST_DIR}",
            "file_operations"
        )
        
        # ãƒ†ã‚¹ãƒˆ4: è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ
        self.measure_task(
            "Multiple file operations",
            f"Create three files in {TEST_DIR}: file1.txt with 'First file', file2.txt with 'Second file', file3.txt with 'Third file'",
            "file_operations"
        )
    
    def run_text_generation_tests(self):
        """ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ“ Text Generation Tests")
        print("=" * 50)
        
        # ãƒ†ã‚¹ãƒˆ1: çŸ­æ–‡ç”Ÿæˆ
        self.measure_task(
            "Short text (haiku)",
            "Write a haiku about distributed systems",
            "text_generation"
        )
        
        # ãƒ†ã‚¹ãƒˆ2: ä¸­æ–‡ç”Ÿæˆ
        self.measure_task(
            "Medium text (paragraph)",
            "Write a 100-word paragraph explaining microservices architecture",
            "text_generation"
        )
        
        # ãƒ†ã‚¹ãƒˆ3: é•·æ–‡ç”Ÿæˆ
        self.measure_task(
            "Long text (essay)",
            "Write a 500-word essay about the future of AI in software development",
            "text_generation"
        )
        
        # ãƒ†ã‚¹ãƒˆ4: ãƒªã‚¹ãƒˆç”Ÿæˆ
        self.measure_task(
            "Structured list",
            "Create a numbered list of 10 best practices for Python programming",
            "text_generation"
        )
    
    def run_code_generation_tests(self):
        """ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ’» Code Generation Tests")
        print("=" * 50)
        
        # ãƒ†ã‚¹ãƒˆ1: ç°¡å˜ãªé–¢æ•°
        self.measure_task(
            "Simple function",
            "Write a Python function to calculate factorial of a number",
            "code_generation"
        )
        
        # ãƒ†ã‚¹ãƒˆ2: ã‚¯ãƒ©ã‚¹å®Ÿè£…
        self.measure_task(
            "Class implementation",
            "Write a Python class for a simple todo list with add, remove, and list methods",
            "code_generation"
        )
        
        # ãƒ†ã‚¹ãƒˆ3: ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
        self.measure_task(
            "Algorithm implementation",
            "Implement quicksort algorithm in Python with comments",
            "code_generation"
        )
        
        # ãƒ†ã‚¹ãƒˆ4: Web API
        self.measure_task(
            "REST API endpoint",
            "Write a Flask REST API endpoint for user registration with validation",
            "code_generation"
        )
    
    def run_analysis_tests(self):
        """åˆ†æã‚¿ã‚¹ã‚¯ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ” Analysis Tests")
        print("=" * 50)
        
        # ãƒ†ã‚¹ãƒˆ1: è¦ç´„
        self.measure_task(
            "Text summarization",
            "Summarize the key concepts of object-oriented programming in 3 bullet points",
            "analysis"
        )
        
        # ãƒ†ã‚¹ãƒˆ2: æ¯”è¼ƒåˆ†æ
        self.measure_task(
            "Comparison analysis",
            "Compare and contrast SQL and NoSQL databases, listing 3 advantages of each",
            "analysis"
        )
        
        # ãƒ†ã‚¹ãƒˆ3: å•é¡Œè§£æ±º
        self.measure_task(
            "Problem solving",
            "A web application is running slowly. List 5 possible causes and solutions",
            "analysis"
        )
        
        # ãƒ†ã‚¹ãƒˆ4: è¨­è¨ˆææ¡ˆ
        self.measure_task(
            "System design",
            "Design a high-level architecture for a real-time chat application",
            "analysis"
        )
    
    def run_translation_tests(self):
        """ç¿»è¨³ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸŒ Translation Tests")
        print("=" * 50)
        
        # ãƒ†ã‚¹ãƒˆ1: æŠ€è¡“æ–‡æ›¸ç¿»è¨³ï¼ˆè‹±â†’æ—¥ï¼‰
        self.measure_task(
            "Technical translation (ENâ†’JP)",
            "Translate to Japanese: 'Kubernetes is an open-source container orchestration platform that automates deployment, scaling, and management of containerized applications.'",
            "translation"
        )
        
        # ãƒ†ã‚¹ãƒˆ2: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç¿»è¨³
        self.measure_task(
            "Error message translation",
            "Translate this error message to user-friendly Japanese: 'Error: Connection timeout. The server did not respond within the specified time limit.'",
            "translation"
        )
        
        # ãƒ†ã‚¹ãƒˆ3: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç¿»è¨³
        self.measure_task(
            "Documentation translation",
            "Translate to Japanese and keep technical terms in English: 'To install Python packages, use pip install command. Virtual environments are recommended for project isolation.'",
            "translation"
        )
    
    def run_stress_test(self):
        """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆéåŒæœŸã‚¿ã‚¹ã‚¯ï¼‰"""
        print("\nâš¡ Stress Test (Async Tasks)")
        print("=" * 50)
        
        # 5ã¤ã®éåŒæœŸã‚¿ã‚¹ã‚¯ã‚’åŒæ™‚æŠ•å…¥
        tasks = []
        for i in range(5):
            result = self.measure_task(
                f"Async task {i+1}",
                f"Generate a random 5-line poem about the number {i+1}",
                "text_generation",
                sync=False
            )
            tasks.append(result)
            time.sleep(0.5)  # å°‘ã—é–“éš”ã‚’ç©ºã‘ã‚‹
        
        return tasks
    
    def generate_report(self):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\n" + "=" * 70)
        print("ğŸ“Š BENCHMARK REPORT")
        print("=" * 70)
        
        # å…¨ä½“çµ±è¨ˆ
        total_tests = len(self.results)
        successful_tests = sum(1 for r in self.results if r.get("success", False))
        sync_tests = [r for r in self.results if r.get("sync", True)]
        
        print(f"\nğŸ“ˆ Overall Statistics:")
        print(f"  â€¢ Total tests: {total_tests}")
        print(f"  â€¢ Successful: {successful_tests}/{total_tests} ({successful_tests/total_tests*100:.1f}%)")
        print(f"  â€¢ Average response time: {statistics.mean([r['time'] for r in sync_tests if 'time' in r]):.2f}s")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        print(f"\nğŸ“Š Category Performance:")
        for category, tests in self.test_categories.items():
            if tests:
                sync_category_tests = [t for t in tests if t.get("sync", True)]
                if sync_category_tests:
                    avg_time = statistics.mean([t['time'] for t in sync_category_tests if 'time' in t])
                    success_rate = sum(1 for t in tests if t.get("success", False)) / len(tests) * 100
                    print(f"\n  {category.upper()}:")
                    print(f"    â€¢ Tests: {len(tests)}")
                    print(f"    â€¢ Success rate: {success_rate:.1f}%")
                    print(f"    â€¢ Avg time: {avg_time:.2f}s")
                    
                    # å€‹åˆ¥ãƒ†ã‚¹ãƒˆçµæœ
                    for test in sync_category_tests:
                        status = "âœ…" if test.get("success", False) else "âŒ"
                        print(f"      {status} {test['name']}: {test.get('time', 0):.2f}s")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œèƒ½åŠ›è©•ä¾¡
        file_ops = self.test_categories.get("file_operations", [])
        file_ops_success = sum(1 for t in file_ops if t.get("success", False))
        
        print(f"\nğŸ”§ Special Capabilities:")
        if file_ops_success > 0:
            print(f"  âœ… File Operations: SUPPORTED ({file_ops_success}/{len(file_ops)} tests passed)")
        else:
            print(f"  âŒ File Operations: NOT SUPPORTED")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
        print(f"\nâš¡ Performance Rating:")
        avg_response = statistics.mean([r['time'] for r in sync_tests if 'time' in r])
        if avg_response < 5:
            rating = "EXCELLENT"
            stars = "â­â­â­â­â­"
        elif avg_response < 10:
            rating = "GOOD"
            stars = "â­â­â­â­"
        elif avg_response < 20:
            rating = "AVERAGE"
            stars = "â­â­â­"
        else:
            rating = "NEEDS IMPROVEMENT"
            stars = "â­â­"
        
        print(f"  â€¢ Rating: {rating} {stars}")
        print(f"  â€¢ Response time: {avg_response:.2f}s average")
        
        # ä¿å­˜
        report_file = Path(f"/home/hama/project/koubou-system/benchmark_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        with open(report_file, 'w') as f:
            json.dump({
                "timestamp": datetime.now().isoformat(),
                "summary": {
                    "total_tests": total_tests,
                    "successful_tests": successful_tests,
                    "success_rate": successful_tests/total_tests*100 if total_tests > 0 else 0,
                    "average_response_time": avg_response,
                    "file_operations_supported": file_ops_success > 0
                },
                "categories": self.test_categories,
                "detailed_results": self.results
            }, f, indent=2)
        
        print(f"\nğŸ’¾ Report saved to: {report_file}")
        print("=" * 70)
        
        return report_file


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
    print("ğŸ­ å·¥æˆ¿ã‚·ã‚¹ãƒ†ãƒ  ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ")
    print("Starting at:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    
    # ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒç¢ºèª
    print("\nğŸ” Checking system status...")
    try:
        response = requests.get("http://localhost:8765/health", timeout=5)
        if response.status_code == 200:
            print("  âœ… MCP Server is running")
        else:
            print("  âŒ MCP Server is not responding properly")
            return
    except:
        print("  âŒ Cannot connect to MCP Server. Please start the system first.")
        print("  Run: .koubou/start_system.sh")
        return
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    benchmark = BenchmarkTest()
    
    # å„ãƒ†ã‚¹ãƒˆã‚«ãƒ†ã‚´ãƒªã‚’å®Ÿè¡Œ
    benchmark.run_file_operation_tests()
    benchmark.run_text_generation_tests()
    benchmark.run_code_generation_tests()
    benchmark.run_analysis_tests()
    benchmark.run_translation_tests()
    benchmark.run_stress_test()
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_file = benchmark.generate_report()
    
    print(f"\nâœ… Benchmark completed successfully!")
    print(f"ğŸ“Š Results saved to: {report_file}")


if __name__ == "__main__":
    main()