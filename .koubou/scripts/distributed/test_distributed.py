#!/usr/bin/env python3
"""
åˆ†æ•£ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
import time
import json
import threading
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from distributed.message_queue import get_queue_instance
from distributed.master_node import MasterNode
from distributed.remote_worker_node import RemoteWorkerNode


def test_local_queue():
    """ãƒ­ãƒ¼ã‚«ãƒ«ã‚­ãƒ¥ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n=== Testing Local Queue ===")
    
    queue = get_queue_instance('local')
    queue.connect()
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    received = {'count': 0}
    
    def on_message(data):
        received['count'] += 1
        print(f"Received message {received['count']}: {data}")
    
    # è³¼èª­
    queue.subscribe('test_channel', on_message)
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
    for i in range(3):
        message = {
            'id': i,
            'content': f'Test message {i}',
            'timestamp': datetime.now().isoformat()
        }
        queue.publish('test_channel', message)
        time.sleep(0.1)
    
    # å—ä¿¡å¾…ã¡
    time.sleep(1)
    
    assert received['count'] == 3, f"Expected 3 messages, got {received['count']}"
    print(f"âœ… Local queue test passed: {received['count']} messages")
    
    queue.disconnect()


def test_master_worker_communication():
    """ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒ¯ãƒ¼ã‚«ãƒ¼é–“é€šä¿¡ãƒ†ã‚¹ãƒˆ"""
    print("\n=== Testing Master-Worker Communication ===")
    
    # ãƒã‚¹ã‚¿ãƒ¼ãƒãƒ¼ãƒ‰èµ·å‹•
    master_config = {
        'node_id': 'test-master',
        'location': 'local',
        'queue_type': 'local',
        'routing_strategy': 'load_balanced'
    }
    
    master = MasterNode(master_config)
    assert master.start(), "Failed to start master node"
    print("âœ… Master node started")
    
    # ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒ‰èµ·å‹•
    worker_config = {
        'node_id': 'test-worker-01',
        'location': 'local',
        'queue_type': 'local',
        'capacity': {
            'max_workers': 2,
            'max_memory_gb': 4,
            'has_gpu': False
        },
        'capabilities': ['general', 'test'],
        'llm_config': {
            'type': 'mock',  # ãƒ†ã‚¹ãƒˆç”¨ãƒ¢ãƒƒã‚¯
            'model': 'test-model'
        }
    }
    
    # ãƒ¢ãƒƒã‚¯LLMå®Ÿè¡Œã‚’è¿½åŠ 
    def mock_execute(self, prompt):
        return f"Mock response for: {prompt[:50]}..."
    
    RemoteWorkerNode._execute_general_task = mock_execute
    
    worker = RemoteWorkerNode(worker_config)
    
    # ãƒã‚¹ã‚¿ãƒ¼ã«æ¥ç¶šï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãªã®ã§å³åº§ã«ï¼‰
    time.sleep(0.5)  # ãƒã‚¹ã‚¿ãƒ¼èµ·å‹•å¾…ã¡
    assert worker.connect_to_master('localhost'), "Failed to connect worker to master"
    print("âœ… Worker connected to master")
    
    # ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒç™»éŒ²ã•ã‚ŒãŸã‹ç¢ºèª
    time.sleep(1)
    status = master.get_status()
    assert status['nodes']['registered'] == 1, "Worker not registered"
    assert status['nodes']['active'] == 1, "Worker not active"
    print(f"âœ… Worker registered: {status['nodes']['details']}")
    
    # ã‚¿ã‚¹ã‚¯é€ä¿¡ãƒ†ã‚¹ãƒˆ
    test_task = {
        'id': 'test-task-001',
        'type': 'general',
        'content': 'Test prompt for distributed processing',
        'priority': 5
    }
    
    assert master.assign_task(test_task), "Failed to assign task"
    print("âœ… Task assigned to worker")
    
    # ã‚¿ã‚¹ã‚¯å‡¦ç†å¾…ã¡
    time.sleep(2)
    
    # çµ±è¨ˆç¢ºèª
    master_status = master.get_status()
    worker_status = worker.get_status()
    
    print(f"Master stats: {master_status['stats']}")
    print(f"Worker stats: {worker_status['stats']}")
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    worker.disconnect()
    master.stop()
    
    print("âœ… Master-Worker communication test passed")


def test_load_balancing():
    """è² è·åˆ†æ•£ãƒ†ã‚¹ãƒˆ"""
    print("\n=== Testing Load Balancing ===")
    
    # ãƒã‚¹ã‚¿ãƒ¼ãƒãƒ¼ãƒ‰èµ·å‹•
    master = MasterNode({
        'node_id': 'lb-master',
        'location': 'local',
        'queue_type': 'local',
        'routing_strategy': 'load_balanced'
    })
    master.start()
    
    # è¤‡æ•°ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•
    workers = []
    for i in range(3):
        worker_config = {
            'node_id': f'lb-worker-{i:02d}',
            'location': 'local',
            'queue_type': 'local',
            'capacity': {'max_workers': 2},
            'capabilities': ['general'],
            'llm_config': {'type': 'mock'}
        }
        
        worker = RemoteWorkerNode(worker_config)
        RemoteWorkerNode._execute_general_task = lambda self, p: f"Response from {self.node_id}"
        
        worker.connect_to_master('localhost')
        workers.append(worker)
    
    time.sleep(1)
    
    # è¤‡æ•°ã‚¿ã‚¹ã‚¯é€ä¿¡
    for i in range(10):
        task = {
            'id': f'lb-task-{i:03d}',
            'type': 'general',
            'content': f'Load balance test task {i}',
            'priority': 5
        }
        master.assign_task(task)
        time.sleep(0.1)
    
    # å‡¦ç†å¾…ã¡
    time.sleep(3)
    
    # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã®è² è·ç¢ºèª
    print("Worker load distribution:")
    for worker in workers:
        status = worker.get_status()
        print(f"  {status['node_id']}: {status['stats']['tasks_received']} tasks")
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    for worker in workers:
        worker.disconnect()
    master.stop()
    
    print("âœ… Load balancing test passed")


def test_node_failure_recovery():
    """ãƒãƒ¼ãƒ‰éšœå®³ã¨ãƒªã‚«ãƒãƒªãƒ¼ãƒ†ã‚¹ãƒˆ"""
    print("\n=== Testing Node Failure & Recovery ===")
    
    master = MasterNode({
        'node_id': 'recovery-master',
        'location': 'local',
        'queue_type': 'local'
    })
    master.start()
    
    # ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•
    worker1 = RemoteWorkerNode({
        'node_id': 'recovery-worker-01',
        'location': 'local',
        'queue_type': 'local',
        'capabilities': ['general']
    })
    worker1.connect_to_master('localhost')
    
    time.sleep(1)
    
    # ãƒ¯ãƒ¼ã‚«ãƒ¼1ã‚’åˆ‡æ–­ï¼ˆéšœå®³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    print("Simulating worker failure...")
    worker1.disconnect()
    
    time.sleep(2)
    
    # ãƒã‚¹ã‚¿ãƒ¼ãŒãƒ¯ãƒ¼ã‚«ãƒ¼ã®åˆ‡æ–­ã‚’æ¤œçŸ¥ã—ãŸã‹ç¢ºèª
    status = master.get_status()
    active_count = status['nodes']['active']
    print(f"Active nodes after failure: {active_count}")
    
    # æ–°ã—ã„ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’èµ·å‹•ï¼ˆãƒªã‚«ãƒãƒªãƒ¼ï¼‰
    print("Starting recovery worker...")
    worker2 = RemoteWorkerNode({
        'node_id': 'recovery-worker-02',
        'location': 'local',
        'queue_type': 'local',
        'capabilities': ['general']
    })
    worker2.connect_to_master('localhost')
    
    time.sleep(1)
    
    # ãƒªã‚«ãƒãƒªãƒ¼ç¢ºèª
    status = master.get_status()
    assert status['nodes']['active'] >= 1, "Recovery worker not active"
    print(f"âœ… Recovery successful: {status['nodes']['active']} active nodes")
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    worker2.disconnect()
    master.stop()


def run_all_tests():
    """å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("=" * 60)
    print("ğŸ§ª Distributed Worker System Tests")
    print("=" * 60)
    
    try:
        # å„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        test_local_queue()
        test_master_worker_communication()
        test_load_balancing()
        test_node_failure_recovery()
        
        print("\n" + "=" * 60)
        print("âœ… All tests passed successfully!")
        print("=" * 60)
        
    except AssertionError as e:
        print(f"\nâŒ Test failed: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    run_all_tests()