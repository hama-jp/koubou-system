a new main()


⫻const:repo_name
deniskropp/gemini-repo-cli


⫻context/file:src/gemini_repo/api.py
import os
import logging
import json
from typing import List, Optional

# Note: google-genai library needs to be installed
# pip install google-genai
try:
    from google.genai import Client
    from google.genai.types import GenerateContentConfig
except ImportError:
    print("ERROR: google-genai library not found. Please install it: pip install google-genai")
    exit(1)


# Constants
DEFAULT_MODEL = 'gemini-2.0-flash' # Updated default model

# Get logger for this module. Configuration is handled by the application using this library.
logger = logging.getLogger(__name__)


class GeminiRepoAPI:
    """
    Interacts with the Google Gemini API to generate content based on repository context.

    This class encapsulates the logic for authenticating with the Gemini API,
    constructing prompts with file context, sending requests, and processing responses.
    """

    def __init__(self, api_key: Optional[str] = None, model_name: str = DEFAULT_MODEL):
        """
        Initializes the GeminiRepoAPI client.

        Args:
            api_key: The Google Gemini API key. If None, attempts to read from
                     the GEMINI_API_KEY environment variable.
            model_name: The name of the Gemini model to use (e.g., 'gemini-2.5-pro-exp-03-25').

        Raises:
            ValueError: If the API key is not provided and not found in the environment.
            Exception: If the Google Gemini client fails to initialize.
        """
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        if not self.api_key:
            log_data = {"event": "init_failed", "reason": "API key missing"}
            logger.error(log_data)
            raise ValueError("GEMINI_API_KEY not provided or set in environment variables.")

        self.model_name = model_name
        try:
            # Initialize the Google Gemini client
            self.client = Client(api_key=self.api_key)
            log_data = {"event": "client_init", "status": "success", "model_name": self.model_name}
            logger.info(log_data)
        except Exception as e:
            log_data = {"event": "client_init", "status": "failed", "error": str(e)}
            logger.exception(log_data) # Use exception to include traceback
            raise Exception(f"Failed to initialize Google Gemini client: {e}")

        # Configure generation parameters
        # candidate_count: Number of responses to generate.
        # temperature: Controls randomness (lower means more deterministic).
        # max_output_tokens: Limits the length of the generated response.
        self.generation_config = GenerateContentConfig(
            candidate_count=1,
            temperature=0.2, # Slightly increased for potentially more creative code gen
            max_output_tokens=8192 # Increased token limit for larger files
        )
        log_data = {
            "event": "config_set",
            "generation_config": {
                "candidate_count": self.generation_config.candidate_count,
                "temperature": self.generation_config.temperature,
                "max_output_tokens": self.generation_config.max_output_tokens
            }
        }
        logger.debug(log_data)

    def generate_content(self, repo_name: str, file_paths: List[str], target_file_name: str, prompt: str) -> str:
        """
        Generates content for a target file using context from other files.

        Constructs a structured prompt including the repository name, contents of
        specified files, and the user's request, then sends it to the Gemini API.

        Args:
            repo_name: The name of the repository (used for context).
            file_paths: A list of paths to files whose content should be included
                        in the prompt context.
            target_file_name: The name/path of the file the generated content is intended for.
            prompt: The user's core instruction or question for the generation.

        Returns:
            The generated content as a single string.

        Raises:
            FileNotFoundError: If any file in `file_paths` cannot be read.
            Exception: If an error occurs during API communication or content generation.
        """
        try:
            model_inputs = self._create_prompt_inputs(repo_name, file_paths, target_file_name, prompt)
            log_data = {"event": "prompt_created", "num_input_parts": len(model_inputs)}
            logger.debug(log_data)

            with open('prompt.txt', mode='w') as f:
                f.write("\n\n\n".join(model_inputs))

            # Select the specific model instance
            #model_instance = [self.model_name]

            # Generate content using the streaming API for potentially long responses
            #response_stream = model_instance.generate_content(
            #    contents=model_inputs,
            #    generation_config=self.generation_config,
            #    stream=True
            #)
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=model_inputs,
                config=self.generation_config
            )
            log_data = {"event": "generation_request_sent", "model": self.model_name}
            logger.info(log_data)

            generated_content_parts = []
            generated_content_parts.append(response.text)


            generated_content = "".join(generated_content_parts)

            log_data = {"event": "generation_complete", "status": "success", "output_length": len(generated_content)}
            logger.info(log_data)

            return generated_content

        except FileNotFoundError as e:
             # Log specific file not found errors from _read_file_content via _create_prompt_inputs
            log_data = {"event": "generation_failed", "reason": "context_file_not_found", "error": str(e)}
            logger.error(log_data)
            raise  # Re-raise the specific error
        except Exception as e:
            log_data = {"event": "generation_failed", "reason": "api_error", "error": str(e)}
            logger.exception(log_data) # Use exception for traceback
            raise Exception(f"An error occurred during content generation: {e}")

    def _read_file_content(self, file_path: str) -> str:
        """
        Reads the content of a single file.

        Args:
            file_path: The path to the file.

        Returns:
            The content of the file as a string.

        Raises:
            FileNotFoundError: If the file does not exist at the specified path.
            IOError: If any other error occurs during file reading.
        """
        log_data = {"event": "read_file_attempt", "file_path": file_path}
        logger.debug(log_data)
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
                log_data.update({"status": "success", "file_size_bytes": len(content.encode('utf-8'))})
                logger.debug(log_data)
                return content
        except FileNotFoundError:
            log_data.update({"status": "failed", "error": "File not found"})
            logger.error(log_data)
            # Raise specific error to be caught by the caller
            raise FileNotFoundError(f"Context file not found: {file_path}")
        except Exception as e:
            log_data.update({"status": "failed", "error": str(e)})
            logger.exception(log_data)
             # Raise a more general error for other issues
            raise IOError(f"Error reading file {file_path}: {e}")

    def _create_prompt_inputs(
        self, repo_name: str, file_paths: List[str], target_file_name: str, initial_prompt: str
    ) -> List:
        """
        Constructs the structured input list for the Gemini API.

        The prompt is assembled using KickLang-like tags for context clarity:
        - `⫻const:repo_name`: Identifies the repository.
        - `⫻context/file:{file_path}`: Provides content from context files.
        - The final part specifies the target file and the core generation task.

        Args:
            repo_name: The repository name.
            file_paths: List of context file paths.
            target_file_name: The target file name for generation.
            initial_prompt: The user's core prompt/instruction.

        Returns:
            A list suitable for the `contents` parameter of the Gemini API's
            `generate_content` method.

        Raises:
            FileNotFoundError: If `_read_file_content` fails for any file.
            IOError: If `_read_file_content` fails for any file.
        """
        # Start with the main user prompt and repository context
        # Using a list of strings/parts per turn, as recommended for multimodal input later
        # For text-only now, simple strings work, but this structure is flexible.
        model_inputs = [initial_prompt, f"⫻const:repo_name\n{repo_name}"]
        log_data = {"event": "prompt_build_start", "repo_name": repo_name}
        logger.debug(log_data)

        # Add context from each specified file
        for file_path in file_paths:
            try:
                file_content = self._read_file_content(file_path) # Can raise FileNotFoundError/IOError
                # Append file context using a specific tag
                model_inputs.append(f"⫻context/file:{file_path}\n{file_content}")
                log_data = {"event": "prompt_add_context", "file_path": file_path, "file_size_bytes": len(file_content.encode('utf-8'))}
                logger.debug(log_data)
            except (FileNotFoundError, IOError) as e:
                 # Log is handled in _read_file_content, just re-raise
                 raise e

        # Add the final instruction specifying the target file
        model_inputs.append(f"Generate content for the file: {target_file_name}\n")
        log_data = {"event": "prompt_build_complete", "target_file_name": target_file_name}
        logger.debug(log_data)

        # The API expects a list where each item represents a turn or a cohesive block.
        # For simple text prompts, often a single list containing all parts works.
        # Let's structure it as a single list of strings for now.
        return model_inputs



⫻context/file:src/gemini_repo/cli.py
import argparse
import os
import sys
import logging
import json
import time
from logging import StreamHandler, Formatter
from gemini_repo import GeminiRepoAPI


# --- Constants ---

# Use default from API class
from gemini_repo.api import DEFAULT_MODEL


# --- JSON Logging Setup ---

class JsonFormatter(Formatter):
    """
    Formats log records as JSON strings (JSONL format - one JSON object per line).
    """
    def format(self, record):
        log_record = {
            "timestamp": self.formatTime(record, self.datefmt),
            "level": record.levelname,
            "name": record.name,
            #"pathname": record.pathname, # Optional: file path
            #"lineno": record.lineno,     # Optional: line number
        }
        # If the log message is a dictionary, merge it
        if isinstance(record.msg, dict):
            log_record.update(record.msg)
        else:
            log_record["message"] = record.getMessage()

        # Add exception info if present
        if record.exc_info:
            # formatException typically returns a multi-line string; replace newlines
            log_record['exception'] = self.formatException(record.exc_info).replace('\n', '\\n')
        if record.stack_info:
             log_record['stack_info'] = self.formatStack(record.stack_info).replace('\n', '\\n')

        return json.dumps(log_record)

def setup_logging(debug=False):
    """Configures logging to output JSONL to stderr."""
    log_level = logging.DEBUG if debug else logging.INFO
    logger = logging.getLogger() # Get root logger
    logger.setLevel(log_level)

    # Remove existing handlers to avoid duplicates if run multiple times
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)

    # Create handler and formatter
    handler = StreamHandler(sys.stderr) # Log to stderr
    formatter = JsonFormatter(datefmt='%Y-%m-%dT%H:%M:%S%z') # ISO 8601 format

    # Set formatter and add handler
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    # Set level for the specific logger of this module
    logging.getLogger(__name__).setLevel(log_level)
    # Optionally set levels for other libraries if needed (e.g., reduce verbosity)
    # logging.getLogger('google').setLevel(logging.WARNING)


# --- Main CLI Logic ---

def main():
    """
    Command-Line Interface for generating file content using GeminiRepoAPI.

    Parses arguments, sets up logging, initializes the API, calls the
    content generation method, and handles output to stdout or a file.
    """
    parser = argparse.ArgumentParser(
        description="Generate content for a target file using Google Gemini API and repository context.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter # Show default values in help
    )
    parser.add_argument(
        "repo_name",
        help="The logical name of the repository (used for context in the prompt)."
    )
    parser.add_argument(
        "target_file",
        help="The name/path of the target file to generate content for."
    )
    parser.add_argument(
        "prompt",
        help="The core prompt/instruction to guide content generation."
    )
    parser.add_argument(
        "--files", "-f",
        nargs="+",
        default=[],
        metavar="FILE_PATH",
        help="Space-separated list of file paths to include as context.",
    )
    parser.add_argument(
        "--api-key", "-k", # Changed short flag to avoid conflict if adding key file option later
        dest="api_key", # Explicit destination name
        default=None, # Default to None, API class will check env var
        help="Google Gemini API key. Overrides GEMINI_API_KEY environment variable if provided."
    )
    parser.add_argument(
        "--model", "-m",
        default=DEFAULT_MODEL,
        help="Name of the Gemini model to use."
    )
    parser.add_argument(
        "--output", "-o",
        metavar="OUTPUT_FILE",
        help="Path to the file where generated content will be written. If omitted, output to stdout."
    )
    parser.add_argument(
        "--debug", "-d",
        action="store_true",
        help="Enable DEBUG level logging."
    )

    args = parser.parse_args()

    # --- Setup Logging ---
    setup_logging(debug=args.debug)
    logger = logging.getLogger(__name__) # Get logger for this module
    start_time = time.time()
    logger.info({"event": "cli_start", "args": vars(args)}) # Log arguments securely if needed

    # --- Initialize API ---
    api_instance = None # Initialize to None
    try:
        api_instance = GeminiRepoAPI(api_key=args.api_key, model_name=args.model)
        logger.info({"event": "api_init", "status": "success"})
    except ValueError as e:
        logger.error({"event": "api_init", "status": "failed", "error": str(e)})
        print(f"ERROR: Initialization failed: {e}", file=sys.stderr)
        sys.exit(1) # Exit with error code
    except Exception as e:
        logger.exception({"event": "api_init", "status": "failed", "error": str(e)})
        print(f"ERROR: Unexpected error during initialization: {e}", file=sys.stderr)
        sys.exit(1)

    # --- Generate Content ---
    generated_content = None
    try:
        logger.info({"event": "generation_start", "target_file": args.target_file, "context_files": args.files})
        generation_start_time = time.time()

        generated_content = api_instance.generate_content(
            repo_name=args.repo_name,
            file_paths=args.files,
            target_file_name=args.target_file,
            prompt=args.prompt,
        )

        generation_duration = time.time() - generation_start_time
        logger.info({
            "event": "generation_end",
            "status": "success",
            "duration_seconds": round(generation_duration, 3),
            "output_length": len(generated_content)
        })

    except FileNotFoundError as e:
         # Specific handling for file not found during generation (logged in API, but good to note here too)
        logger.error({"event": "generation_end", "status": "failed", "reason": "context_file_not_found", "error": str(e)})
        print(f"ERROR: Could not read context file: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        logger.exception({"event": "generation_end", "status": "failed", "reason": "api_error", "error": str(e)})
        print(f"ERROR: Failed to generate content: {e}", file=sys.stderr)
        sys.exit(1)

    # --- Output Content ---
    output_destination = args.output if args.output else "stdout"
    try:
        if args.output:
            # Create directories if they don't exist
            output_dir = os.path.dirname(args.output)
            if output_dir: # Ensure it's not an empty string (e.g., file in current dir)
                 os.makedirs(output_dir, exist_ok=True)

            with open(args.output, "w", encoding='utf-8') as f:
                f.write(generated_content)
            logger.info({"event": "output_write", "status": "success", "destination": args.output})
            print(f"Content successfully written to {args.output}", file=sys.stderr) # User feedback to stderr
        else:
            # Print generated content directly to standard output
            print(generated_content)
            logger.info({"event": "output_write", "status": "success", "destination": "stdout"})

    except Exception as e:
        logger.exception({"event": "output_write", "status": "failed", "destination": output_destination, "error": str(e)})
        print(f"ERROR: Failed to write output to {output_destination}: {e}", file=sys.stderr)
        sys.exit(1)

    total_duration = time.time() - start_time
    logger.info({"event": "cli_end", "status": "success", "total_duration_seconds": round(total_duration, 3)})


if __name__ == "__main__":
    main()



⫻context/file:src/gemini_repo/__init__.py
from .api import GeminiRepoAPI



Generate content for the file: src/main.py
